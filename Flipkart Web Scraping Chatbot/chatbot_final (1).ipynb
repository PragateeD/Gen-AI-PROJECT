{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-I4NeRGiUGh",
    "outputId": "d9959ca9-2849-41c4-ac09-d2ad204bc5d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: cohere in /usr/local/lib/python3.11/dist-packages (5.15.0)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.59-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.33.2)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.0.20250328)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.30.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.59-py3-none-any.whl (437 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.7/437.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-core, langchain\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.56\n",
      "    Uninstalling langchain-core-0.3.56:\n",
      "      Successfully uninstalled langchain-core-0.3.56\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.24\n",
      "    Uninstalling langchain-0.3.24:\n",
      "      Successfully uninstalled langchain-0.3.24\n",
      "Successfully installed langchain-0.3.25 langchain-core-0.3.59\n"
     ]
    }
   ],
   "source": [
    "# 1. Install Dependencies\n",
    "!pip install -q langchain-community langchain-core faiss-cpu gradio pandas sentence-transformers cohere\n",
    "!pip install --upgrade langchain cohere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPqzBDNkiW9_"
   },
   "outputs": [],
   "source": [
    "# 2. Import Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Cohere\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.documents import Document\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHGN3mdFihKm"
   },
   "outputs": [],
   "source": [
    "# 3. Load & Clean Data (Minimal)\n",
    "# Load raw CSV\n",
    "df = pd.read_csv(\"/content/flipkart_laptop.csv\")\n",
    "\n",
    "# Basic cleaning\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\")\n",
    "df = df.dropna(subset=[\"Description\"])\n",
    "\n",
    "# Fix encoding issues in price\n",
    "df['Prices'] = df['Prices'].astype(str).str.replace(r'[^\\d]', '', regex=True).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uE_3j9qJiuAt"
   },
   "outputs": [],
   "source": [
    "# 4. Create LangChain Documents\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=row['Description'],\n",
    "        metadata={\"name\": row[\"Product_name\"], \"price\": row[\"Prices\"]}\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571,
     "referenced_widgets": [
      "c62d09ae5a84401f902ec345a1fff979",
      "fa28112a19294fe8898bdeae2b63a113",
      "e3b29b6cdfde4b47b3c473b742edf307",
      "158712ffc6bc4e1597e4582d8f70e100",
      "f8021192ce9c4d6d8d8eb8ab64025b11",
      "7083de45e72848f2a35eee4772df1778",
      "18297c1ace5547e7ad623f3e41f50e2f",
      "6058061b0d7749379e1ae693e38b5f63",
      "d6a8d8c9bd5447c5b9b589da3ba7f1ec",
      "fb841165266f40bf8cebb9c7c68a29e0",
      "2de8a2ed16384b20a475463913b3fe14",
      "1b72c8a213334501967e8f078a044105",
      "ade24de82633449c9fbfd2ee270a4d3b",
      "33cd31a3badf450586ca7792fe6a7661",
      "520c911fa5d443f2832668afcc97677a",
      "5979b3866c0d48429eafa72f45a5407e",
      "6961d95598964879916698b4f515c1a7",
      "356be54fac654eb988f2d134f2e572b4",
      "0b109022c8c74982bae574ebb938d1de",
      "49824ce99cf74f968b07a6731ffc60a1",
      "da0a0a01dc8f4e28b5e598378cef47a8",
      "97a8360498ea4ec292b9912f70f79732",
      "a5b49c6c68d84e35b5f6ff4708857536",
      "4d0380eb481641feb779061265e21781",
      "f38f652beb6a4d6a95da459da5f401f8",
      "8819d60b68324740a1ae56535b8e1670",
      "81e9293af8ea445885536514b4c6d99e",
      "cbd9003654a34eceb269a4c4603feea8",
      "d678f22e215b4734a85b56637d4b157e",
      "02e07ebc9d9442528c82ddfd0f70db3c",
      "348a8945c55f4eedaafe392c7ad4983f",
      "ffd04dc3b3a64671950373b2d3c2ed28",
      "638ca1c38dcc4550b039fec4e7975e5d",
      "f1edc4c58bad4ea08d9e5e24bad26533",
      "1872e037226349c2a75df0ab1fc514ea",
      "84ef9622abae4c4aa3aacf0b507c0176",
      "c530baaf135742af8da5cf7e47fc364f",
      "72fa390bf1ae4379ad71398d0d582132",
      "4d7495d4ba19438b882c9b4b09d541f3",
      "46efb0601068457fa20135dc9fc65221",
      "af0fdddadc9945f4b942e78dc08bf820",
      "6f92ac8467dd4353bd97fdd9408ba4f2",
      "531c744dfca34469b5eb5817b814df3b",
      "50ebffbfdcbb481db374703381fb0c57",
      "5068ab4d06a34ced9bb8d89833ccee74",
      "e2b1df5e12f044a2861101383c163d1c",
      "3bbe02c26d7c40be891189ea725b2947",
      "9093f3c032e14796b53e8b049cc33e34",
      "54c5dea1ecb1466a88f5428ac4cb2e80",
      "a8ead5feb1724feb91553a313da93ee1",
      "b6573ae70d234d94967bee8b413d0251",
      "1407c2ffdb9641bba0b9e6e6144aa1b4",
      "9f6d544cacaa4562b96e486b2b8e16d9",
      "e466725aea9f40e297a19870bcebe032",
      "129a5d4c0f4f4e118e1b6f6c1e6eef5b",
      "ea78a650b6144bb78108f3d350bf087b",
      "8e3583fdc56f4b16a10a1dbdbc5cc126",
      "d88f33f976e04b9bbb37081d93365981",
      "36b311554c79450cbd77f28d81c887b7",
      "49ae92e28d1741ec8db73deaae73252b",
      "565a575cc6354e7ea429ba6259156053",
      "2c379549c8bb467e875c239b3479b7d2",
      "ed8eca7a8e4948fdba25f2513ce8ec27",
      "6baeb6179f94497eac752d7633f67161",
      "64e24a8b9e144513986e074427305571",
      "6b60d6ca26464b4383c8858dabf84743",
      "b045063e7660401f876cdbe2ec3d64e1",
      "2a669033b2704ede9e4f005ac3ca474e",
      "418d95c3de5845929c7c469d2d2e49b7",
      "7ddca5e25ee946fc825be08d4645c321",
      "1241702c93c64e4980e7294bd479b8b6",
      "7c59c417fe074002b4b9dcf0c118e0a5",
      "c5e5aa74e509417e919779c52755b504",
      "9fce41786cd24484a43598e9143a83d8",
      "0b62f36b47a64e8aaa7f8d0ba999845d",
      "e3a7e97ea32b4fe4ba04947fef39ff7b",
      "db7a2fd0cc9848a1afec45e53c0f20d4",
      "77f67e0193584f3abedbe1800b818927",
      "124c77485c574790a03cf9bff81f08d4",
      "6dbfdc9c162f43519d85bded703daba0",
      "4c61b56dd07f469fa9be89e916504a22",
      "deccf87674e8480fa897502c6289a8fa",
      "44b31d9af1f44695b615a49a346d7ee1",
      "81ebc1f6f6cc4204a1e2b7ea93d5d41a",
      "daf73dbece394a9ba80e1cfa6f5a4d80",
      "07457cbc089d48819177f1bc19e8862d",
      "a606a39130b5485b92212117f73c7eae",
      "a8c72ee3038748919834397676bf72a6",
      "98bdb027382c4d5191db6e9b42043c42",
      "c9aa72fe53944bf4b81c833465db5543",
      "fb5b77bdd6a7437daae40afefb3116d8",
      "51a6590ebd714d8d932d8be1497e112b",
      "345cba4fcc9a4537a9919897a3a60671",
      "c4881f20ce274b1a9fb24194f2bb84e2",
      "26148835df38429a921416782d080217",
      "667f132b94bc497d81114470f396e704",
      "39e9f8c2059b4e36afb65a191e36bfde",
      "fb06890335424deb9d52af8c6caac042",
      "4e2093d7df1e4b04be6b3e684c83fdbc",
      "53776702f9a4457c9dda55bb7fed5a6b",
      "3ffd0ff6c22c40bbbfb7499ea8cb8d0c",
      "f74969e7d09947fb978fe541db87ee01",
      "2bb32e331ad344089abfd6aaac5ec565",
      "062e4aa588444d7d98233f8c801e0992",
      "9f3b218f15e747099058504d65d20891",
      "aaa8f46ad64a4da0a279777574ee2582",
      "0f1ee1a136844015b748ef48b911ae41",
      "b71a47db71114ee389ffa77ab7da7994",
      "2d0f2cf55e1f43f88c9b72727206ccbe",
      "5797098a55f84858ae9aad2e49d4cfb6",
      "b87a8e13c8964208bca9f1932647f00f",
      "f128b6fd0bb34100a6f56663dd93e68b",
      "eedb3763eaf3416f9ce9e1fd9a298955",
      "b7e9814fc28d4a6eb1e7394e4fc79d95",
      "9a3b00670ff94f8d8b06adf853d32bfc",
      "a2729e84c65a45298adffba20aadb14b",
      "8e030d22c9ec46429dccb19483f9a27d",
      "1c67112e7cca4f63961727feb1e57faf",
      "136420a449f44ef1bdc7ec8577be2cde",
      "03a6e453fa8142c5b4edc54e0204dfb8",
      "27db74ec63724ebaaa592bb11bc1cb6e"
     ]
    },
    "id": "UFM5GwRJixgD",
    "outputId": "99d9aa4c-8018-40cf-89e3-3ce7329bf288"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-9abcd5c65e83>:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62d09ae5a84401f902ec345a1fff979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b72c8a213334501967e8f078a044105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b49c6c68d84e35b5f6ff4708857536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1edc4c58bad4ea08d9e5e24bad26533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5068ab4d06a34ced9bb8d89833ccee74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea78a650b6144bb78108f3d350bf087b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b045063e7660401f876cdbe2ec3d64e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f67e0193584f3abedbe1800b818927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bdb027382c4d5191db6e9b42043c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53776702f9a4457c9dda55bb7fed5a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87a8e13c8964208bca9f1932647f00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Create FAISS Vectorstore\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzXGxMaOjAPa",
    "outputId": "80c281fd-b2b7-4a74-a1f4-492271858f7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-0cdeafb5c224>:3: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-cohere package and should be used instead. To use it run `pip install -U :class:`~langchain-cohere` and import as `from :class:`~langchain_cohere import Cohere``.\n",
      "  llm = Cohere(cohere_api_key=cohere_api_key)\n"
     ]
    }
   ],
   "source": [
    "# 6. Setup LLM Chain (Cohere)\n",
    "cohere_api_key = \"VhKGyVtrr840QnyCPlDupNO05vA6JSKCCTBxj4ac\"  # Replace this\n",
    "llm = Cohere(cohere_api_key=cohere_api_key)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3jkWafpjGvR"
   },
   "outputs": [],
   "source": [
    "# 7. Define Filtering Logic\n",
    "def extract_price_limit(query):\n",
    "    match = re.search(r'under\\s*₹?\\s*(\\d+)', query)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def respond(query):\n",
    "    price_limit = extract_price_limit(query)\n",
    "    result = qa_chain({\"query\": query})\n",
    "    answer = result[\"result\"]\n",
    "    sources = result[\"source_documents\"]\n",
    "\n",
    "    matching = []\n",
    "    for doc in sources:\n",
    "        meta = doc.metadata\n",
    "        if price_limit is None or int(meta[\"price\"]) <= price_limit:\n",
    "            matching.append(f\"- {meta['name']} (₹{meta['price']})\")\n",
    "\n",
    "    if not matching:\n",
    "        matching.append(\"No exact match under that budget, but here are similar options.\")\n",
    "        matching += [f\"- {doc.metadata['name']} (₹{doc.metadata['price']})\" for doc in sources]\n",
    "\n",
    "    return f\"{answer}\\n\\nMatching Products:\\n\" + \"\\n\".join(matching)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "C9SnrSZ6jMUg",
    "outputId": "6444fc10-b0a0-482c-bd8c-12cda698e993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://ab470c2b7530cf25f3.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ab470c2b7530cf25f3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Create Gradio UI\n",
    "gr.Interface(\n",
    "    fn=respond,\n",
    "    inputs=gr.Textbox(placeholder=\"Ask about laptops (e.g., under ₹50000)...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"💻 Flipkart Laptop Recommender\",\n",
    "    examples=[\n",
    "        \"Best laptops under ₹30000\",\n",
    "        \"Suggest laptop for gaming under 40000\",\n",
    "        \"Give laptops with Intel i5 processor\"\n",
    "    ]\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "ebkGIcjkl8DA",
    "outputId": "f64d961b-7e87-47a4-91a6-9e7b26c3fc19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://aab7c150b71b7025c0.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://aab7c150b71b7025c0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q langchain-community langchain-core faiss-cpu gradio pandas sentence-transformers cohere\n",
    "\n",
    "# ---------------------- Step 1: Imports ----------------------\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import Cohere\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "import gradio as gr\n",
    "\n",
    "# ---------------------- Step 2: Load and Clean Data ----------------------\n",
    "df = pd.read_csv(\"/content/flipkart_laptop.csv\")\n",
    "\n",
    "# Minimal but essential cleaning\n",
    "df = df.dropna(subset=['Description', 'Product_name', 'Prices'])\n",
    "df['Prices'] = df['Prices'].astype(str).str.extract(r'(\\d[\\d,]*)')[0].str.replace(',', '').astype(int)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ---------------------- Step 3: Create Embedding Documents ----------------------\n",
    "def create_docs(df):\n",
    "    docs = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = f\"{row['Product_name']} | {row['Description']} | ₹{row['Prices']}\"\n",
    "        docs.append(Document(\n",
    "            page_content=text,\n",
    "            metadata={\n",
    "                \"name\": row[\"Product_name\"],\n",
    "                \"price\": row[\"Prices\"]\n",
    "            }\n",
    "        ))\n",
    "    return docs\n",
    "\n",
    "documents = create_docs(df)\n",
    "\n",
    "# ---------------------- Step 4: Build Vectorstore ----------------------\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# ---------------------- Step 5: Setup Retrieval QA Chain ----------------------\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=Cohere(cohere_api_key=\"VhKGyVtrr840QnyCPlDupNO05vA6JSKCCTBxj4ac\"),  # Replace with your real key\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# ---------------------- Step 6: Smart Post-Retrieval Filtering ----------------------\n",
    "def extract_filters(query):\n",
    "    price_limit = None\n",
    "    brand = None\n",
    "\n",
    "    # More comprehensive price extraction\n",
    "    price_matches = re.findall(r\"₹?\\s*(\\d+)\\s*(?:to|-|and)\\s*₹?\\s*(\\d+)\", query, re.IGNORECASE)\n",
    "    if price_matches:\n",
    "        price_limit = int(price_matches[0][1])  # Take upper limit\n",
    "    else:\n",
    "        price_match = re.search(r\"(?:under|below|less than)\\s*₹?\\s*(\\d+)\", query, re.IGNORECASE)\n",
    "        if price_match:\n",
    "            price_limit = int(price_match.group(1))\n",
    "\n",
    "    brands = ['acer', 'hp', 'dell', 'lenovo', 'asus', 'msi', 'apple', 'samsung']\n",
    "    for b in brands:\n",
    "        if re.search(rf\"\\b{b}\\b\", query, re.IGNORECASE):\n",
    "            brand = b.lower()\n",
    "            break\n",
    "\n",
    "    return price_limit, brand\n",
    "def respond(query):\n",
    "    price_limit, brand = extract_filters(query)\n",
    "\n",
    "    all_docs = vectorstore.similarity_search(query, k=20)\n",
    "\n",
    "    matches = []\n",
    "    seen_products = set()\n",
    "\n",
    "    for doc in all_docs:\n",
    "        name = doc.metadata[\"name\"]\n",
    "        price = doc.metadata[\"price\"]\n",
    "\n",
    "        if price_limit is not None and price > price_limit:\n",
    "            continue\n",
    "        if brand is not None and brand.lower() not in name.lower():\n",
    "            continue\n",
    "\n",
    "        product_id = f\"{name}_{price}\"\n",
    "        if product_id in seen_products:\n",
    "            continue\n",
    "        seen_products.add(product_id)\n",
    "\n",
    "        matches.append({\n",
    "            \"name\": name,\n",
    "            \"price\": price,\n",
    "            \"doc\": doc\n",
    "        })\n",
    "\n",
    "    matches.sort(key=lambda x: x[\"price\"])\n",
    "\n",
    "    if not matches:\n",
    "        return f\"No {brand.capitalize() if brand else ''} laptops found under ₹{price_limit or 'your budget'}. Try adjusting your requirements.\"\n",
    "\n",
    "    # Dynamic heading\n",
    "    heading = \"Here are\"\n",
    "    if brand:\n",
    "        heading += f\" {brand.capitalize()}\"\n",
    "    heading += \" laptops\"\n",
    "    if price_limit:\n",
    "        heading += f\" under ₹{price_limit}\"\n",
    "    heading += \":\\n\\n\"\n",
    "\n",
    "    response = heading\n",
    "    for match in matches:\n",
    "        response += f\"- {match['name']} (₹{match['price']})\\n\"\n",
    "\n",
    "    return response\n",
    "\n",
    "# ---------------------- Step 7: Gradio UI ----------------------\n",
    "gr.Interface(\n",
    "    fn=respond,\n",
    "    inputs=gr.Textbox(placeholder=\"Ask about laptops...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Laptop Recommender\",\n",
    "    examples=[\n",
    "        \"Best laptops under ₹30000\",\n",
    "        \"Suggest laptop for gaming under 40000\",\n",
    "        \"Give Acer laptops with i5 processor\"\n",
    "    ]\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWJ5QCPXOZF6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
